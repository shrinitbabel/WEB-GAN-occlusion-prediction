{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# dataset\n",
    "df = pd.read_csv('WEB_TARGET.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Sex', 'Ruptured', 'Circulation', 'Location', 'Ignore',\n",
       "       'Max diameter in any dimension (mm)', 'Height (mm)', 'Width (mm)',\n",
       "       'Other diameter', 'Neck (mm) orthogonal view 1',\n",
       "       'Neck (mm) orthogonal view 2', 'Avg neck vol', 'Aneurysm 3D Volume',\n",
       "       'WEB_1_Name', 'SL/Elongated', 'WEB_1_width', 'WEB_1_Height',\n",
       "       'WEB Volume', 'WEB Device #2 name', 'WEB 2 Volume', 'Final WEB Volume',\n",
       "       'Comments on why a second device needed',\n",
       "       'Complete WEB failure/abandonment', 'Re-sizing required',\n",
       "       'Stenting used to support WEB?', 'Composite outcome',\n",
       "       'Procedure related ischemic stroke?', 'Intraop rupture', '3_mo_occ',\n",
       "       '6_mo_occ', '1_year_occ'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Missing Values in Each Feature:\n",
      "Age                                        0.000000\n",
      "Sex                                        0.000000\n",
      "Ruptured                                   0.000000\n",
      "Circulation                                0.000000\n",
      "Location                                   0.000000\n",
      "Ignore                                    70.512821\n",
      "Max diameter in any dimension (mm)         0.000000\n",
      "Height (mm)                                0.000000\n",
      "Width (mm)                                 0.000000\n",
      "Other diameter                            55.128205\n",
      "Neck (mm) orthogonal view 1                0.000000\n",
      "Neck (mm) orthogonal view 2                0.000000\n",
      "Avg neck vol                               0.000000\n",
      "Aneurysm 3D Volume                         0.000000\n",
      "WEB_1_Name                                 0.000000\n",
      "SL/Elongated                               0.000000\n",
      "WEB_1_width                                0.000000\n",
      "WEB_1_Height                               0.000000\n",
      "WEB Volume                                 0.000000\n",
      "WEB Device #2 name                        88.461538\n",
      "WEB 2 Volume                              88.461538\n",
      "Final WEB Volume                           0.000000\n",
      "Comments on why a second device needed    88.461538\n",
      "Complete WEB failure/abandonment           0.000000\n",
      "Re-sizing required                         0.000000\n",
      "Stenting used to support WEB?              0.000000\n",
      "Composite outcome                          0.000000\n",
      "Procedure related ischemic stroke?         0.000000\n",
      "Intraop rupture                            0.000000\n",
      "3_mo_occ                                  87.179487\n",
      "6_mo_occ                                   0.000000\n",
      "1_year_occ                                82.051282\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Alternatively, calculate percentages\n",
    "missing_percent = df.isna().mean() * 100\n",
    "print(\"Percentage of Missing Values in Each Feature:\")\n",
    "print(missing_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/5000 | Loss D: 9.6863 | Loss G: -0.0875 | Temp: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrin\\AppData\\Local\\Temp\\ipykernel_30568\\2992081683.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/5000 | Loss D: 1.1535 | Loss G: 0.3860 | Temp: 0.1850\n",
      "Epoch 1000/5000 | Loss D: 1.7433 | Loss G: 0.0661 | Temp: 0.1700\n",
      "Epoch 1500/5000 | Loss D: 1.7610 | Loss G: 0.0638 | Temp: 0.1550\n",
      "Epoch 2000/5000 | Loss D: 1.6162 | Loss G: 0.1223 | Temp: 0.1400\n",
      "Epoch 2500/5000 | Loss D: 1.6121 | Loss G: 0.1030 | Temp: 0.1250\n",
      "Epoch 3000/5000 | Loss D: 1.8313 | Loss G: 0.0893 | Temp: 0.1100\n",
      "Epoch 3500/5000 | Loss D: 1.7818 | Loss G: 0.0907 | Temp: 0.0950\n",
      "Epoch 4000/5000 | Loss D: 1.8297 | Loss G: 0.1148 | Temp: 0.0800\n",
      "Epoch 4500/5000 | Loss D: 1.4840 | Loss G: 0.2876 | Temp: 0.0650\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Features and data preparation\n",
    "features = ['Age', 'Sex', 'Ruptured', 'Circulation',\n",
    "            'Max diameter in any dimension (mm)', 'Height (mm)',\n",
    "            'Width (mm)', 'Neck (mm) orthogonal view 1',\n",
    "            'Neck (mm) orthogonal view 2', 'Avg neck vol', 'Aneurysm 3D Volume',\n",
    "            'SL/Elongated', 'Final WEB Volume',\n",
    "            'Complete WEB failure/abandonment', 'Re-sizing required',\n",
    "            'Stenting used to support WEB?', 'Composite outcome',\n",
    "            'Procedure related ischemic stroke?', 'Intraop rupture',\n",
    "            '6_mo_occ']\n",
    "\n",
    "data = df[features].copy()\n",
    "\n",
    "ordinal_features = ['6_mo_occ']\n",
    "binary_features = ['Sex', 'Ruptured', 'Circulation', 'SL/Elongated','Composite outcome',\n",
    "                   'Complete WEB failure/abandonment', 'Re-sizing required',\n",
    "                   'Stenting used to support WEB?', 'Intraop rupture',\n",
    "                   'Procedure related ischemic stroke?']\n",
    "continuous_features = [col for col in features if col not in binary_features + ordinal_features]\n",
    "\n",
    "for col in ordinal_features:\n",
    "    data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "data.fillna(data.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "scaler_continuous = MinMaxScaler()\n",
    "scaler_ordinal = MinMaxScaler()\n",
    "data[continuous_features] = scaler_continuous.fit_transform(data[continuous_features])\n",
    "data[ordinal_features] = scaler_ordinal.fit_transform(data[ordinal_features])\n",
    "\n",
    "X = data.values\n",
    "\n",
    "# GAN parameters\n",
    "latent_dim = 16\n",
    "input_dim = X.shape[1]\n",
    "binary_dim = len(binary_features)\n",
    "continuous_dim = len(continuous_features)\n",
    "ordinal_dim = len(ordinal_features)\n",
    "epochs = 5000\n",
    "batch_size = 16\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# Conditional Generator\n",
    "class ConditionalGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim, binary_dim, continuous_dim, ordinal_dim, initial_temperature=0.2):\n",
    "        super(ConditionalGenerator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.binary_dim = binary_dim\n",
    "        self.continuous_dim = continuous_dim\n",
    "        self.ordinal_dim = ordinal_dim\n",
    "        self.temperature = initial_temperature\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim + binary_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, binary_dim + continuous_dim + ordinal_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, z, conditions):\n",
    "        input = torch.cat([z, conditions], dim=1)\n",
    "        logits = self.model(input)\n",
    "        binary_logits = logits[:, :self.binary_dim]\n",
    "        continuous_logits = logits[:, self.binary_dim:self.binary_dim + self.continuous_dim]\n",
    "        ordinal_logits = logits[:, self.binary_dim + self.continuous_dim:]\n",
    "        binary_output = torch.sigmoid(binary_logits / self.temperature)\n",
    "        continuous_output = torch.sigmoid(continuous_logits)\n",
    "        ordinal_output = torch.sigmoid(ordinal_logits)\n",
    "        return torch.cat([binary_output, continuous_output, ordinal_output], dim=1)\n",
    "\n",
    "    def update_temperature(self, new_temperature):\n",
    "        self.temperature = new_temperature\n",
    "\n",
    "# Conditional Discriminator\n",
    "class ConditionalDiscriminator(nn.Module):\n",
    "    def __init__(self, input_dim, binary_dim):\n",
    "        super(ConditionalDiscriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim + binary_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, conditions):\n",
    "        input = torch.cat([x, conditions], dim=1)\n",
    "        return self.model(input)\n",
    "\n",
    "# Hinge Loss\n",
    "def hinge_loss_discriminator(real_scores, fake_scores):\n",
    "    return torch.mean(torch.relu(1.0 - real_scores)) + torch.mean(torch.relu(1.0 + fake_scores))\n",
    "\n",
    "def hinge_loss_generator(fake_scores):\n",
    "    return -torch.mean(fake_scores)\n",
    "\n",
    "# Gradient Penalty\n",
    "def compute_gradient_penalty(discriminator, real_data, fake_data, conditions):\n",
    "    alpha = torch.rand(real_data.size(0), 1).expand_as(real_data)\n",
    "    interpolates = alpha * real_data + (1 - alpha) * fake_data\n",
    "    interpolates = interpolates.requires_grad_(True)\n",
    "    scores = discriminator(interpolates, conditions)\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=scores,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=torch.ones_like(scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradient_norm = gradients.norm(2, dim=1)\n",
    "    return ((gradient_norm - 1) ** 2).mean()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = ConditionalGenerator(latent_dim, binary_dim, continuous_dim, ordinal_dim)\n",
    "discriminator = ConditionalDiscriminator(input_dim, binary_dim)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "# Binary conditions\n",
    "binary_conditions = torch.tensor(X[:, :binary_dim], dtype=torch.float32)\n",
    "\n",
    "# Training\n",
    "initial_temperature = 0.2\n",
    "final_temperature = 0.05\n",
    "temperature_decay = (initial_temperature - final_temperature) / epochs\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    current_temperature = max(final_temperature, initial_temperature - epoch * temperature_decay)\n",
    "    generator.update_temperature(current_temperature)\n",
    "\n",
    "    for _ in range(X.shape[0] // batch_size):\n",
    "        real_idx = np.random.choice(X.shape[0], batch_size)\n",
    "        real_data = torch.tensor(X[real_idx], dtype=torch.float32)\n",
    "        real_conditions = binary_conditions[real_idx]\n",
    "\n",
    "        noise = torch.randn(batch_size, latent_dim)\n",
    "        fake_data = generator(noise, real_conditions)\n",
    "        real_scores = discriminator(real_data, real_conditions)\n",
    "        fake_scores = discriminator(fake_data.detach(), real_conditions)\n",
    "\n",
    "        gp = compute_gradient_penalty(discriminator, real_data, fake_data, real_conditions)\n",
    "\n",
    "        optimizer_d.zero_grad()\n",
    "        loss_d = hinge_loss_discriminator(real_scores, fake_scores) + 10 * gp\n",
    "        loss_d.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        noise = torch.randn(batch_size, latent_dim)\n",
    "        fake_data = generator(noise, real_conditions)\n",
    "        fake_scores = discriminator(fake_data, real_conditions)\n",
    "\n",
    "        optimizer_g.zero_grad()\n",
    "        loss_g = hinge_loss_generator(fake_scores)\n",
    "        loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch {epoch}/{epochs} | Loss D: {loss_d.item():.4f} | Loss G: {loss_g.item():.4f} | Temp: {current_temperature:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Age  Sex  Ruptured  Circulation  Max diameter in any dimension (mm)  \\\n",
      "0  47.396488    1         1            1                            6.670673   \n",
      "1  33.364552    1         1            1                            8.396546   \n",
      "2  57.797279    0         0            1                           10.937903   \n",
      "3  36.825123    0         1            1                            5.799216   \n",
      "4  40.772968    0         0            1                            4.324586   \n",
      "\n",
      "   Height (mm)  Width (mm)  Neck (mm) orthogonal view 1  \\\n",
      "0     6.401578    5.721988                     3.173919   \n",
      "1     8.676097    7.632496                     6.792737   \n",
      "2    10.773809    7.744838                     2.603350   \n",
      "3     5.460171    5.722278                     2.411260   \n",
      "4     4.232851    3.915308                     3.453340   \n",
      "\n",
      "   Neck (mm) orthogonal view 2  Avg neck vol  Aneurysm 3D Volume  \\\n",
      "0                     2.732397      2.767143          125.095436   \n",
      "1                     3.957878      5.575778          271.172180   \n",
      "2                     3.272367      3.063973          275.001495   \n",
      "3                     2.556535      2.031038           26.991043   \n",
      "4                     2.806736      2.871893           32.175888   \n",
      "\n",
      "   SL/Elongated  Final WEB Volume  Complete WEB failure/abandonment  \\\n",
      "0             1        138.501953                                 0   \n",
      "1             0        267.300049                                 0   \n",
      "2             0        265.249878                                 0   \n",
      "3             1         42.390659                                 0   \n",
      "4             1         46.397461                                 0   \n",
      "\n",
      "   Re-sizing required  Stenting used to support WEB?  Composite outcome  \\\n",
      "0                   0                              0                  0   \n",
      "1                   0                              0                  0   \n",
      "2                   0                              0                  0   \n",
      "3                   0                              0                  0   \n",
      "4                   0                              0                  0   \n",
      "\n",
      "   Procedure related ischemic stroke?  Intraop rupture  6_mo_occ  \n",
      "0                                   0                0         0  \n",
      "1                                   0                0         4  \n",
      "2                                   0                0         1  \n",
      "3                                   0                0         0  \n",
      "4                                   0                0         0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate synthetic data\n",
    "num_samples = 1000\n",
    "noise = torch.randn(num_samples, latent_dim)\n",
    "\n",
    "if num_samples > len(binary_conditions):\n",
    "    conditions = binary_conditions.repeat((num_samples // len(binary_conditions)) + 1, 1)[:num_samples]\n",
    "else:\n",
    "    conditions = binary_conditions[:num_samples]\n",
    "\n",
    "synthetic_data = generator(noise, conditions).detach().numpy()\n",
    "\n",
    "# Post-processing\n",
    "synthetic_df = pd.DataFrame(synthetic_data, columns=features)\n",
    "synthetic_df[continuous_features] = scaler_continuous.inverse_transform(synthetic_df[continuous_features])\n",
    "synthetic_df[ordinal_features] = scaler_ordinal.inverse_transform(synthetic_df[ordinal_features])\n",
    "\n",
    "for col in ordinal_features:\n",
    "    synthetic_df[col] = synthetic_df[col].round().astype(int)\n",
    "\n",
    "synthetic_df[binary_features] = synthetic_df[binary_features].round().astype(int)\n",
    "\n",
    "print(synthetic_df.head())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolmogorov-Smirnov Test Results for Continuous Features:\n",
      "                                    KS Statistic   p-value\n",
      "Age                                     0.054795  0.972620\n",
      "Max diameter in any dimension (mm)      0.051231  0.985854\n",
      "Height (mm)                             0.044462  0.997486\n",
      "Width (mm)                              0.121641  0.215245\n",
      "Neck (mm) orthogonal view 1             0.052436  0.982032\n",
      "Neck (mm) orthogonal view 2             0.129564  0.160437\n",
      "Avg neck vol                            0.102744  0.400803\n",
      "Aneurysm 3D Volume                      0.089128  0.580284\n",
      "Final WEB Volume                        0.099949  0.435020\n",
      "\n",
      "Jensen-Shannon Divergence for Continuous Features:\n",
      "                                    Jensen-Shannon Divergence\n",
      "Age                                                  0.286426\n",
      "Max diameter in any dimension (mm)                   0.199746\n",
      "Height (mm)                                          0.194778\n",
      "Width (mm)                                           0.202096\n",
      "Neck (mm) orthogonal view 1                          0.213511\n",
      "Neck (mm) orthogonal view 2                          0.242444\n",
      "Avg neck vol                                         0.244509\n",
      "Aneurysm 3D Volume                                   0.232945\n",
      "Final WEB Volume                                     0.341000\n",
      "\n",
      "Earth Mover's Distance for Continuous Features:\n",
      "                                    Earth Mover's Distance\n",
      "Age                                               1.056287\n",
      "Max diameter in any dimension (mm)                0.090998\n",
      "Height (mm)                                       0.073506\n",
      "Width (mm)                                        0.292482\n",
      "Neck (mm) orthogonal view 1                       0.075448\n",
      "Neck (mm) orthogonal view 2                       0.152554\n",
      "Avg neck vol                                      0.151807\n",
      "Aneurysm 3D Volume                               12.840281\n",
      "Final WEB Volume                                 13.511093\n",
      "\n",
      "Comparison of Proportions for Binary Features:\n",
      "                                    Original Proportion  Synthetic Proportion\n",
      "Sex                                            0.282051                 0.282\n",
      "Ruptured                                       0.128205                 0.130\n",
      "Circulation                                    0.897436                 0.807\n",
      "SL/Elongated                                   0.935897                 0.935\n",
      "Composite outcome                              0.166667                 0.170\n",
      "Complete WEB failure/abandonment               0.000000                 0.000\n",
      "Re-sizing required                             0.115385                 0.130\n",
      "Stenting used to support WEB?                  0.064103                 0.030\n",
      "Intraop rupture                                0.000000                 0.000\n",
      "Procedure related ischemic stroke?             0.025641                 0.023\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp, wasserstein_distance\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import numpy as np\n",
    "\n",
    "def ks_test(original, synthetic):\n",
    "    try:\n",
    "        ks_stat, p_value = ks_2samp(original, synthetic)\n",
    "        return {\"KS Statistic\": ks_stat, \"p-value\": p_value}\n",
    "    except Exception as e:\n",
    "        return {\"KS Statistic\": None, \"p-value\": None, \"Error\": str(e)}\n",
    "\n",
    "def js_divergence(original, synthetic, bins=30):\n",
    "    try:\n",
    "        original_hist, _ = np.histogram(original, bins=bins, density=True)\n",
    "        synthetic_hist, _ = np.histogram(synthetic, bins=bins, density=True)\n",
    "        jsd = jensenshannon(original_hist, synthetic_hist)\n",
    "        return jsd\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def emd(original, synthetic):\n",
    "    try:\n",
    "        emd_value = wasserstein_distance(original, synthetic)\n",
    "        return emd_value\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Kolmogorov-Smirnov Test\n",
    "ks_results = {feature: ks_test(df[feature].dropna(), synthetic_df[feature].dropna()) for feature in continuous_features}\n",
    "\n",
    "# Jensen-Shannon Divergence\n",
    "jsd_results = {feature: js_divergence(df[feature].dropna(), synthetic_df[feature].dropna()) for feature in continuous_features}\n",
    "\n",
    "# Earth Mover's Distance (Wasserstein Distance)\n",
    "emd_results = {feature: emd(df[feature].dropna(), synthetic_df[feature].dropna()) for feature in continuous_features}\n",
    "\n",
    "# Binary features comparison\n",
    "binary_comparison = {feature: {\"Original Proportion\": df[feature].mean(skipna=True), \"Synthetic Proportion\": synthetic_df[feature].mean(skipna=True)} for feature in binary_features}\n",
    "\n",
    "# Convert results to DataFrames for easier analysis\n",
    "ks_results_df = pd.DataFrame(ks_results).T\n",
    "jsd_results_df = pd.DataFrame(jsd_results, index=[\"Jensen-Shannon Divergence\"]).T\n",
    "emd_results_df = pd.DataFrame(emd_results, index=[\"Earth Mover's Distance\"]).T\n",
    "binary_comparison_df = pd.DataFrame(binary_comparison).T\n",
    "\n",
    "print(\"Kolmogorov-Smirnov Test Results for Continuous Features:\")\n",
    "print(ks_results_df)\n",
    "\n",
    "print(\"\\nJensen-Shannon Divergence for Continuous Features:\")\n",
    "print(jsd_results_df)\n",
    "\n",
    "print(\"\\nEarth Mover's Distance for Continuous Features:\")\n",
    "print(emd_results_df)\n",
    "\n",
    "print(\"\\nComparison of Proportions for Binary Features:\")\n",
    "print(binary_comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolmogorov-Smirnov Test Results for Ordinal Features:\n",
      "          KS Statistic   p-value\n",
      "6_mo_occ      0.054051  0.975898\n",
      "\n",
      "Jensen-Shannon Divergence for Ordinal Features:\n",
      "          Jensen-Shannon Divergence\n",
      "6_mo_occ                   0.106894\n",
      "\n",
      "Frequency Comparison for Ordinal Features:\n",
      "\n",
      "6_mo_occ Frequency Comparison:\n",
      "          Original  Synthetic\n",
      "6_mo_occ                     \n",
      "0         0.538462      0.494\n",
      "1         0.102564      0.130\n",
      "2         0.076923      0.148\n",
      "3         0.256410      0.183\n",
      "4         0.025641      0.045\n"
     ]
    }
   ],
   "source": [
    "ks_results_ordinal = {}\n",
    "jsd_results_ordinal = {}\n",
    "freq_comparison_ordinal = {}\n",
    "\n",
    "for feature in ordinal_features:\n",
    "    try:\n",
    "        # Drop missing values for both real and synthetic datasets\n",
    "        original = df[feature].dropna()\n",
    "        synthetic = synthetic_df[feature].dropna()\n",
    "\n",
    "        # KS Test\n",
    "        ks_stat, p_value = ks_2samp(original, synthetic)\n",
    "        ks_results_ordinal[feature] = {\"KS Statistic\": ks_stat, \"p-value\": p_value}\n",
    "\n",
    "        # Jensen-Shannon Divergence\n",
    "        num_bins = max(len(original.unique()), len(synthetic.unique()))\n",
    "        original_hist, _ = np.histogram(original, bins=num_bins, range=(original.min(), original.max()), density=True)\n",
    "        synthetic_hist, _ = np.histogram(synthetic, bins=num_bins, range=(original.min(), original.max()), density=True)\n",
    "        jsd = jensenshannon(original_hist, synthetic_hist)\n",
    "        jsd_results_ordinal[feature] = jsd\n",
    "\n",
    "        # Frequency Comparison\n",
    "        original_freq = original.value_counts(normalize=True).sort_index()\n",
    "        synthetic_freq = synthetic.value_counts(normalize=True).sort_index()\n",
    "        freq_comparison = pd.DataFrame({'Original': original_freq, 'Synthetic': synthetic_freq}).fillna(0)\n",
    "        freq_comparison_ordinal[feature] = freq_comparison\n",
    "\n",
    "    except Exception as e:\n",
    "        ks_results_ordinal[feature] = {\"KS Statistic\": None, \"p-value\": None, \"Error\": str(e)}\n",
    "        jsd_results_ordinal[feature] = None\n",
    "        freq_comparison_ordinal[feature] = None\n",
    "\n",
    "ks_results_ordinal_df = pd.DataFrame(ks_results_ordinal).T\n",
    "jsd_results_ordinal_df = pd.DataFrame(jsd_results_ordinal, index=[\"Jensen-Shannon Divergence\"]).T\n",
    "\n",
    "print(\"Kolmogorov-Smirnov Test Results for Ordinal Features:\")\n",
    "print(ks_results_ordinal_df)\n",
    "\n",
    "print(\"\\nJensen-Shannon Divergence for Ordinal Features:\")\n",
    "print(jsd_results_ordinal_df)\n",
    "\n",
    "print(\"\\nFrequency Comparison for Ordinal Features:\")\n",
    "for feature, comparison in freq_comparison_ordinal.items():\n",
    "    if comparison is not None:\n",
    "        print(f\"\\n{feature} Frequency Comparison:\")\n",
    "        print(comparison)\n",
    "    else:\n",
    "        print(f\"\\n{feature} Frequency Comparison: None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_df.to_csv('synthetic_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
